{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第7章\n",
    "モデルのアンサンブル手法を学ぶ。\n",
    "\n",
    "---\n",
    "ソースコードは以下から引用しています: https://github.com/ghmagazine/kagglebook/tree/master/ch07\n",
    "\n",
    "ライセンス: https://github.com/ghmagazine/kagglebook/blob/master/LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スタッキング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# train_xは学習データ、train_yは目的変数、test_xはテストデータ\n",
    "# pandasのDataFrame, Seriesで保持します。（numpyのarrayで保持することもあります）\n",
    "\n",
    "train = pd.read_csv('data/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('data/sample-data/test_preprocessed.csv')\n",
    "\n",
    "# neural net用のデータ\n",
    "train_nn = pd.read_csv('data/sample-data/train_preprocessed_onehot.csv')\n",
    "train_x_nn = train_nn.drop(['target'], axis=1)\n",
    "train_y_nn = train_nn['target']\n",
    "test_x_nn = pd.read_csv('data/sample-data/test_preprocessed_onehot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# tensorflowの警告抑制\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "\n",
    "# xgboostによるモデル\n",
    "class Model1Xgb:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71,\n",
    "                  'eval_metric': 'logloss'}\n",
    "        num_round = 10\n",
    "        dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        self.model = xgb.train(params, dtrain, num_round, evals=watchlist)\n",
    "\n",
    "    def predict(self, x):\n",
    "        data = xgb.DMatrix(x)\n",
    "        pred = self.model.predict(data)\n",
    "        return pred\n",
    "\n",
    "\n",
    "# ニューラルネットによるモデル\n",
    "class Model1NN:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "\n",
    "        batch_size = 128\n",
    "        epochs = 5\n",
    "\n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        va_x = self.scaler.transform(va_x)\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, activation='relu', input_shape=(tr_x.shape[1],)))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(256, activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "        history = model.fit(tr_x, tr_y,\n",
    "                            batch_size=batch_size, epochs=epochs,\n",
    "                            verbose=1, validation_data=(va_x, va_y))\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict_proba(x).reshape(-1)\n",
    "        return pred\n",
    "\n",
    "\n",
    "# 線形モデル\n",
    "class Model2Linear:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(tr_x)\n",
    "        tr_x = self.scaler.transform(tr_x)\n",
    "        self.model = LogisticRegression(solver='lbfgs', C=1.0)\n",
    "        self.model.fit(tr_x, tr_y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = self.scaler.transform(x)\n",
    "        pred = self.model.predict_proba(x)[:, 1]\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### スタッキング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# 学習データに対する「目的変数を知らない」予測値と、テストデータに対する予測値を返す関数\n",
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds_val = []  # 各foldにおける(valid以外の)trainで学習したモデルのvalidに対する予測を格納\n",
    "    preds_test = []  # 各foldにおけるtestに対する予測を格納\n",
    "    va_idxes = []  # 各foldにおいてvaldとして割り当てられたデータのインデックスを格納\n",
    "\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "\n",
    "    # クロスバリデーションで学習・予測を行い、予測値とインデックスを保存する\n",
    "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y, va_x, va_y)  # trainで学習, valは学習経過のバリデーションに使用\n",
    "        pred_val = model.predict(va_x)  # このfoldにおいて(valid以外の)trainで学習したモデルを使ってvalidに対して予測\n",
    "        preds_val.append(pred_val)\n",
    "        pred_test = model.predict(test_x)  # このfoldにおいて(valid以外の)trainで学習したモデルを使ってtest（foldに関わらず同じデータ）に対して予測\n",
    "        preds_test.append(pred_test)\n",
    "        va_idxes.append(va_idx)\n",
    "    # - - - クロスバリデーション終わり - - -\n",
    "\n",
    "    # バリデーションデータに対する予測値を連結し、その後元の順序に並べ直す\n",
    "    va_idxes = np.concatenate(va_idxes)\n",
    "    preds_val = np.concatenate(preds_val, axis=0)\n",
    "    # どうしてインデックスを昇順にソートし直す必要がある？\n",
    "    # → preds_valの並びはKFold.split()によってランダムになっており、\n",
    "    #     このままだとモデル評価（log_loss()の箇所）時に、特徴量preds_valとラベルtrain_yが正しく対応しないから\n",
    "    #     （preds_valをインデックス昇順にソートすることで、train_yの並びと合うようになる）\n",
    "    order = np.argsort(va_idxes)  # va_idxesを昇順ソートした後のインデックス\n",
    "    pred_train = preds_val[order]\n",
    "    \n",
    "    # テストデータに対する予測値の平均をとる\n",
    "    # （平均ではなく、学習データ全体に対して学習し直したモデルで予測する方法もある（P.366参照））\n",
    "    preds_test_mean = np.mean(preds_test, axis=0)\n",
    "    \n",
    "    return pred_train, preds_test_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1層目：オリジナルの学習データで学習したモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.540879\teval-logloss:0.550034\n",
      "[1]\ttrain-logloss:0.452692\teval-logloss:0.47182\n",
      "[2]\ttrain-logloss:0.394818\teval-logloss:0.42026\n",
      "[3]\ttrain-logloss:0.351976\teval-logloss:0.385203\n",
      "[4]\ttrain-logloss:0.320213\teval-logloss:0.361498\n",
      "[5]\ttrain-logloss:0.296733\teval-logloss:0.344634\n",
      "[6]\ttrain-logloss:0.276105\teval-logloss:0.329003\n",
      "[7]\ttrain-logloss:0.258858\teval-logloss:0.316697\n",
      "[8]\ttrain-logloss:0.243628\teval-logloss:0.30775\n",
      "[9]\ttrain-logloss:0.231527\teval-logloss:0.300925\n",
      "[0]\ttrain-logloss:0.538915\teval-logloss:0.548639\n",
      "[1]\ttrain-logloss:0.452188\teval-logloss:0.471485\n",
      "[2]\ttrain-logloss:0.395742\teval-logloss:0.419976\n",
      "[3]\ttrain-logloss:0.354763\teval-logloss:0.384132\n",
      "[4]\ttrain-logloss:0.322183\teval-logloss:0.356264\n",
      "[5]\ttrain-logloss:0.299451\teval-logloss:0.339098\n",
      "[6]\ttrain-logloss:0.277833\teval-logloss:0.325516\n",
      "[7]\ttrain-logloss:0.263263\teval-logloss:0.315733\n",
      "[8]\ttrain-logloss:0.247804\teval-logloss:0.30592\n",
      "[9]\ttrain-logloss:0.233693\teval-logloss:0.295955\n",
      "[0]\ttrain-logloss:0.543319\teval-logloss:0.55058\n",
      "[1]\ttrain-logloss:0.454371\teval-logloss:0.468302\n",
      "[2]\ttrain-logloss:0.397123\teval-logloss:0.417626\n",
      "[3]\ttrain-logloss:0.354126\teval-logloss:0.380859\n",
      "[4]\ttrain-logloss:0.32187\teval-logloss:0.358236\n",
      "[5]\ttrain-logloss:0.297691\teval-logloss:0.338343\n",
      "[6]\ttrain-logloss:0.278216\teval-logloss:0.325787\n",
      "[7]\ttrain-logloss:0.260498\teval-logloss:0.313077\n",
      "[8]\ttrain-logloss:0.244367\teval-logloss:0.300156\n",
      "[9]\ttrain-logloss:0.230988\teval-logloss:0.293314\n",
      "[0]\ttrain-logloss:0.541658\teval-logloss:0.550119\n",
      "[1]\ttrain-logloss:0.453088\teval-logloss:0.469646\n",
      "[2]\ttrain-logloss:0.394388\teval-logloss:0.419325\n",
      "[3]\ttrain-logloss:0.353657\teval-logloss:0.382863\n",
      "[4]\ttrain-logloss:0.319021\teval-logloss:0.357915\n",
      "[5]\ttrain-logloss:0.291875\teval-logloss:0.338238\n",
      "[6]\ttrain-logloss:0.272894\teval-logloss:0.326276\n",
      "[7]\ttrain-logloss:0.256689\teval-logloss:0.315504\n",
      "[8]\ttrain-logloss:0.238942\teval-logloss:0.303753\n",
      "[9]\ttrain-logloss:0.227008\teval-logloss:0.296455\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.4333 - val_loss: 0.3759\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.3611 - val_loss: 0.3720\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3366 - val_loss: 0.3589\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3171 - val_loss: 0.3549\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.2914 - val_loss: 0.3414\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 0.4474 - val_loss: 0.3850\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3692 - val_loss: 0.3713\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3422 - val_loss: 0.3576\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3270 - val_loss: 0.3441\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3016 - val_loss: 0.3339\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.4378 - val_loss: 0.3710\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3715 - val_loss: 0.3606\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 0s 28us/step - loss: 0.3465 - val_loss: 0.3494\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3263 - val_loss: 0.3409\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 0s 29us/step - loss: 0.3091 - val_loss: 0.3270\n",
      "Train on 7500 samples, validate on 2500 samples\n",
      "Epoch 1/5\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4549 - val_loss: 0.3772\n",
      "Epoch 2/5\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.3670 - val_loss: 0.3581\n",
      "Epoch 3/5\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.3465 - val_loss: 0.3525\n",
      "Epoch 4/5\n",
      "7500/7500 [==============================] - 0s 26us/step - loss: 0.3239 - val_loss: 0.3470\n",
      "Epoch 5/5\n",
      "7500/7500 [==============================] - 0s 27us/step - loss: 0.2981 - val_loss: 0.3395\n",
      "logloss: 0.2967\n",
      "logloss: 0.3355\n"
     ]
    }
   ],
   "source": [
    "# 1層目のモデル\n",
    "# pred_train_1a, pred_train_1bは、各foldのモデルのバリデーションデータに対する予測値\n",
    "# pred_test_1a, pred_test_1bは、各foldのモデルのテストデータに対する予測値の平均\n",
    "# （pred_train_xx, pred_test_xxはいずれも、予測対象のレコードの目的変数を見ていない状況で学習したモデルによる予測値）\n",
    "model_1a = Model1Xgb()\n",
    "pred_train_1a, pred_test_1a = predict_cv(model_1a, train_x, train_y, test_x)\n",
    "\n",
    "model_1b = Model1NN()\n",
    "pred_train_1b, pred_test_1b = predict_cv(model_1b, train_x_nn, train_y, test_x_nn)\n",
    "\n",
    "# 1層目のモデルの評価\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1a, eps=1e-7):.4f}')\n",
    "print(f'logloss: {log_loss(train_y, pred_train_1b, eps=1e-7):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測値を特徴量としてデータフレームを作成\n",
    "train_x_2 = pd.DataFrame({'pred_1a': pred_train_1a, 'pred_1b': pred_train_1b})\n",
    "test_x_2 = pd.DataFrame({'pred_1a': pred_test_1a, 'pred_1b': pred_test_1b})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_1a</th>\n",
       "      <th>pred_1b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052786</td>\n",
       "      <td>0.145576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.189076</td>\n",
       "      <td>0.077340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.431136</td>\n",
       "      <td>0.339443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.042489</td>\n",
       "      <td>0.020771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.256559</td>\n",
       "      <td>0.679355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_1a   pred_1b\n",
       "0  0.052786  0.145576\n",
       "1  0.189076  0.077340\n",
       "2  0.431136  0.339443\n",
       "3  0.042489  0.020771\n",
       "4  0.256559  0.679355"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_1a</th>\n",
       "      <th>pred_1b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.299180</td>\n",
       "      <td>0.577786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155138</td>\n",
       "      <td>0.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075771</td>\n",
       "      <td>0.032241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.045092</td>\n",
       "      <td>0.004192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.047573</td>\n",
       "      <td>0.012028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pred_1a   pred_1b\n",
       "0  0.299180  0.577786\n",
       "1  0.155138  0.049900\n",
       "2  0.075771  0.032241\n",
       "3  0.045092  0.004192\n",
       "4  0.047573  0.012028"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2層目：「1層目のモデルでの予測値」という特徴量を用いて学習したモデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.2740\n"
     ]
    }
   ],
   "source": [
    "# 2層目のモデル\n",
    "model_2 = Model2Linear()\n",
    "pred_train_2, pred_test_2 = predict_cv(model_2, train_x_2, train_y, test_x_2)\n",
    "print(f'logloss: {log_loss(train_y, pred_train_2, eps=1e-7):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
